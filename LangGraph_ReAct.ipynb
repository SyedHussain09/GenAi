{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langgraph langchain_google_genai langchain_core"
      ],
      "metadata": {
        "id": "xh74qvlcW0lM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.utils.function_calling import convert_to_openai_function\n",
        "from langchain_core.tools import tool\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "ucCqRbM-eETZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "GsTidEVSeNkm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3)"
      ],
      "metadata": {
        "id": "TL8_bJP_eSCe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def search_internet(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Use this tool to search the internet for up-to-date information.\n",
        "    The input is the search query itself.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nTOOL CALLED: Searching for '{query}' \\n\")\n",
        "    if \"latest langgraph\" in query.lower():\n",
        "        return \"The latest official documentation on LangGraph confirms the use of a `messages` list in the State, and recommends using `StateGraph` for custom agent flows.\"\n",
        "    return f\"Information about '{query}' is available.\"\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind_tools([search_internet])\n",
        "\n",
        "print(\"Setup complete. LLM and Tool initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lznW6IDer_m",
        "outputId": "e429681d-9138-4362-ed3e-f88577ef29ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. LLM and Tool initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, List\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
        "import operator\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    # 'messages' is the key that holds the conversation history.\n",
        "    # Annotated[..., operator.add] means new lists of messages are appended to the existing list.\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "\n",
        "print(\"AgentState defined: It stores all 'messages' (conversation history).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5SspHLYfFxI",
        "outputId": "3c36918a-5af2-4dc9-b3d7-b23301b07785"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AgentState defined: It stores all 'messages' (conversation history).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node 1: The Decision Maker (LLM)\n",
        "def run_agent(state: AgentState) -> dict:\n",
        "    \"\"\"Invokes the LLM to get a response or a tool call.\"\"\"\n",
        "    print(\"NODE: Running Agent (Decision Making)\")\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "\n",
        "    result = llm_with_tools.invoke(messages)\n",
        "\n",
        "\n",
        "    return {\"messages\": [result]}\n",
        "\n",
        "# Node 2: The Action Taker (Tool Executor)\n",
        "def execute_tool(state: AgentState) -> dict:\n",
        "    \"\"\"Executes the tool call requested by the LLM.\"\"\"\n",
        "    print(\"NODE: Executing Tool\")\n",
        "\n",
        "\n",
        "    tool_calls = state[\"messages\"][-1].tool_calls\n",
        "\n",
        "\n",
        "    first_tool_call = tool_calls[0]\n",
        "    tool_name = first_tool_call[\"name\"]\n",
        "    tool_args = first_tool_call[\"args\"]\n",
        "\n",
        "\n",
        "    if tool_name == \"search_internet\":\n",
        "\n",
        "        tool_output = search_internet.func(**tool_args)\n",
        "    else:\n",
        "        tool_output = f\"Unknown tool: {tool_name}\"\n",
        "\n",
        "\n",
        "    tool_message = ToolMessage(\n",
        "        content=tool_output,\n",
        "        name=tool_name,\n",
        "\n",
        "        tool_call_id=first_tool_call[\"id\"],\n",
        "    )\n",
        "\n",
        "\n",
        "    return {\"messages\": [tool_message]}"
      ],
      "metadata": {
        "id": "8FlL7PCOfcZK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "\n",
        "def decide_next_step(state: AgentState) -> str:\n",
        "    \"\"\"\n",
        "    Decides whether to execute a tool or end the conversation based on the LLM's response.\n",
        "    Returns: \"continue\" (to tool node) or \"end\" (to final answer).\n",
        "    \"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "\n",
        "\n",
        "    if last_message.tool_calls:\n",
        "\n",
        "        print(\"EDGE: Tool call detected. Moving to 'tools' node.\")\n",
        "        return \"tools\"\n",
        "    else:\n",
        "        print(\"EDGE: Final answer detected. Ending graph execution.\")\n",
        "        return \"end\"\n",
        "\n"
      ],
      "metadata": {
        "id": "K4DWc1w0f544"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"agent\", run_agent)\n",
        "workflow.add_node(\"tools\", execute_tool)\n",
        "\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    decide_next_step,\n",
        "    {\n",
        "        \"tools\": \"tools\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge('tools', 'agent')\n",
        "\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "tEeUWyKMiYNn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "initial_state = {\"messages\": [HumanMessage(content=\"What is the latest guidance for building agents with LangGraph?\")]}\n",
        "\n",
        "print(\"Agent Execution Stream Started\")\n",
        "\n",
        "print(\"-\" * 30)\n",
        "for step in app.stream(initial_state):\n",
        "    node_name = list(step.keys())[0]\n",
        "    print(f\"-> Node executed: **{node_name}**\")\n",
        "\n",
        "final_state = app.invoke(initial_state)\n",
        "\n",
        "final_messages = final_state[\"messages\"]\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(\"\\n FINAL ANSWER from Agent\")\n",
        "print(final_messages[-1].content)\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4iF34uwifT0",
        "outputId": "cfe08ac9-0b82-41f1-d030-d218dbce70d8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent Execution Stream Started\n",
            "------------------------------\n",
            "--- NODE: Running Agent (Decision Making) ---\n",
            "EDGE: Tool call detected. Moving to 'tools' node.\n",
            "-> Node executed: **agent**\n",
            "--- NODE: Executing Tool ---\n",
            "\n",
            "--- TOOL CALLED: Searching for 'latest guidance for building agents with LangGraph' ---\n",
            "\n",
            "-> Node executed: **tools**\n",
            "--- NODE: Running Agent (Decision Making) ---\n",
            "EDGE: Final answer detected. Ending graph execution.\n",
            "-> Node executed: **agent**\n",
            "--- NODE: Running Agent (Decision Making) ---\n",
            "EDGE: Tool call detected. Moving to 'tools' node.\n",
            "--- NODE: Executing Tool ---\n",
            "\n",
            "--- TOOL CALLED: Searching for 'LangGraph agent building latest guidance' ---\n",
            "\n",
            "--- NODE: Running Agent (Decision Making) ---\n",
            "EDGE: Final answer detected. Ending graph execution.\n",
            "------------------------------\n",
            "\n",
            " FINAL ANSWER from Agent\n",
            "[{'type': 'text', 'text': \"I found that information about LangGraph agent building guidance is available. LangGraph is a library that helps build robust and stateful multi-actor applications with LLMs, ideal for creating complex agentic behaviors. It extends LangChain by allowing you to create cyclic graphs, which are essential for agent runtimes that involve multiple steps and decision points.\\n\\nWhile I can confirm that guidance is available, I don't have the ability to directly process and summarize the specific, most up-to-date guidance from the search results in detail. For the latest and most comprehensive guidance on building agents with LangGraph, I recommend consulting the official LangGraph documentation and recent tutorials or articles on the subject, which my search indicates are available online.\", 'extras': {'signature': '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'}}]\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WY0wCgt5i-ZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}