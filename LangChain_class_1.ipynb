{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9nzlHzJJzLK",
        "outputId": "012ca455-b70b-42c6-c43d-11578980f382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-1.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-4.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.56)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.12.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.53.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.54.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (4.12.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Downloading langchain_core-1.2.0-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.9/475.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-4.0.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-core, langchain-google-genai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.1.3\n",
            "    Uninstalling langchain-core-1.1.3:\n",
            "      Successfully uninstalled langchain-core-1.1.3\n",
            "Successfully installed filetype-1.2.0 langchain-core-1.2.0 langchain-google-genai-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain-core langchain-google-genai google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "assert os.environ[\"GOOGLE_API_KEY\"] is not None\n"
      ],
      "metadata": {
        "id": "2HZyFmKYJ2Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"models/gemini-2.5-flash\",\n",
        "    temperature=0.3\n",
        ")\n"
      ],
      "metadata": {
        "id": "_TrymNA4J8Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful GenAI tutor.\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{history}\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "FneBVwWeKAPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n"
      ],
      "metadata": {
        "id": "pvsMbio7KIKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "\n",
        "chat_history = InMemoryChatMessageHistory()\n"
      ],
      "metadata": {
        "id": "WTe4uKkdKMK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "chain_with_memory = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    lambda session_id: chat_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "EKcVwG5YLAfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"session-1\"}}\n",
        "\n",
        "print(chain_with_memory.invoke(\n",
        "    {\"input\": \"Explain LangChain simply\"},\n",
        "    config=config\n",
        "))\n",
        "\n",
        "print(chain_with_memory.invoke(\n",
        "    {\"input\": \"Give a real-world example\"},\n",
        "    config=config\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn5HbUOfLFTU",
        "outputId": "f925d90f-85e5-4935-ece6-ff227d692d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine you have a super-smart friend (that's your **Large Language Model** like ChatGPT). This friend is brilliant at understanding and generating text, but they have a few limitations:\n",
            "\n",
            "1.  **They only know what they were trained on:** They don't know about *your* specific documents, the latest news, or your company's internal data.\n",
            "2.  **They can only talk:** They can't *do* things like search the web, run code, send emails, or interact with other applications.\n",
            "3.  **They have a short memory:** In a long conversation, they might forget what was said earlier.\n",
            "4.  **Doing complex multi-step tasks is hard:** You'd have to manually prompt them, wait for a response, then manually take that response and give it to another tool, and so on.\n",
            "\n",
            "---\n",
            "\n",
            "**This is where LangChain comes in!**\n",
            "\n",
            "Think of **LangChain** as a **developer toolkit or a framework** that helps you build powerful applications *around* Large Language Models.\n",
            "\n",
            "---\n",
            "\n",
            "**The Simple Analogy:**\n",
            "\n",
            "Imagine your LLM (the super-smart friend) is a brilliant **chef**. They know all about cooking theory, ingredients, and recipes in their head. But to actually make a meal, they need:\n",
            "\n",
            "*   **A kitchen:** That's LangChain, providing the structure.\n",
            "*   **Ingredients:** LangChain helps them access *your* data (private documents, databases, web content).\n",
            "*   **Utensils and appliances:** LangChain helps them use *tools* (like searching the internet, calling an API, running Python code).\n",
            "*   **A recipe book that updates:** LangChain gives them a \"memory\" so they remember what they've cooked before or what you asked for earlier.\n",
            "*   **A plan to combine steps:** LangChain helps string together multiple actions (e.g., first search for ingredients, then decide what to cook, then follow a recipe).\n",
            "\n",
            "---\n",
            "\n",
            "**In essence, LangChain helps your LLM \"chef\" do these key things:**\n",
            "\n",
            "1.  **Connect to External Data:** \"Read\" your own documents, databases, or the live internet. (This is often called **Retrieval Augmented Generation - RAG**).\n",
            "2.  **Use Tools and Interact with the World:** \"Act\" by performing searches, calling APIs, sending emails, or running code.\n",
            "3.  **Remember Conversations:** Have a \"memory\" of past interactions in a chat.\n",
            "4.  **Chain Actions Together:** Automate complex multi-step processes where the LLM makes decisions along the way (e.g., \"Find the answer to X, if not found, then search Google, then summarize the result\").\n",
            "\n",
            "---\n",
            "\n",
            "**What can you build with LangChain?**\n",
            "\n",
            "*   **Sophisticated Chatbots:** That answer questions based on your specific company documents or the latest real-time information.\n",
            "*   **AI Agents:** That can perform tasks for you, like researching a topic, drafting an email, or summarizing a long article.\n",
            "*   **Data Analysis Tools:** That interpret data, generate insights, and even visualize them, all driven by natural language.\n",
            "\n",
            "---\n",
            "\n",
            "**The Bottom Line:**\n",
            "\n",
            "**LangChain makes LLMs more useful by giving them the \"hands\" to interact with the real world, the \"eyes\" to see your specific data, and the \"memory\" to have coherent, multi-turn interactions.** It bridges the gap between a powerful language model and a fully functional application.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y5jMgwQmKSIC",
        "outputId": "fbe5ae13-da8e-4967-82ec-a9aa13dfb80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine GenAI as a super-smart, super-creative assistant that can *make* brand new stuff, not just recognize or analyze existing things.\n",
            "\n",
            "Here are the key concepts for an interview, explained super simply:\n",
            "\n",
            "---\n",
            "\n",
            "### 1. What is Generative AI (GenAI)?\n",
            "\n",
            "*   **Simple Idea:** It's a type of Artificial Intelligence that can **create new content** that's original and never existed before.\n",
            "*   **Examples:**\n",
            "    *   Writing an email, story, or poem (like ChatGPT).\n",
            "    *   Making a unique image from a text description (like Midjourney or DALL-E).\n",
            "    *   Composing music, writing code, or even designing products.\n",
            "*   **Analogy:** Think of it as a highly skilled artist, writer, or programmer who can generate new ideas and execute them, rather than just analyzing someone else's work.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. How Does It Work (The \"Magic\" Behind It)?\n",
            "\n",
            "*   **Simple Idea:** GenAI models learn from a *massive* amount of existing data (text, images, code, etc.) and then use that knowledge to predict and generate new content.\n",
            "*   **How it learns:** Imagine a student who reads millions of books, articles, websites, and sees millions of pictures. It learns patterns, grammar, styles, facts, and how things are related.\n",
            "*   **How it creates:** When you give it a prompt (an instruction), it uses all that learned knowledge to predict the most logical \"next word,\" \"next pixel,\" or \"next line of code\" to create something new that fits your request.\n",
            "*   **Key Takeaway:** It's like an incredibly good predictor, based on everything it has \"seen\" or \"read.\"\n",
            "\n",
            "---\n",
            "\n",
            "### 3. Key Terms You'll Hear:\n",
            "\n",
            "*   **LLM (Large Language Model):**\n",
            "    *   **Simple Idea:** This is the big brain specifically for **text**. It's trained on tons of human language to understand and generate text.\n",
            "    *   **Examples:** ChatGPT, Google Gemini.\n",
            "*   **Prompt Engineering:**\n",
            "    *   **Simple Idea:** It's the art of **giving clear and effective instructions** to the AI.\n",
            "    *   **Analogy:** Like knowing exactly what to say to a chef to get the perfect meal. The better your prompt, the better the AI's output.\n",
            "*   **Fine-tuning:**\n",
            "    *   **Simple Idea:** Taking an existing GenAI model and giving it a **smaller, very specific dataset** to make it better at a particular task or topic.\n",
            "    *   **Analogy:** You teach a general chef to become a specialist in Italian cuisine by giving them only Italian recipes to study.\n",
            "*   **RAG (Retrieval Augmented Generation):**\n",
            "    *   **Simple Idea:** Before answering your question, the AI first **looks up specific, up-to-date information** from a trusted source (like your company's documents or a specific database) and then uses that info to generate its answer.\n",
            "    *   **Why it's cool:** It helps prevent the AI from making things up (hallucinating) and ensures it uses accurate, relevant data.\n",
            "    *   **Analogy:** Instead of guessing, the chef quickly consults a specific recipe book before cooking your meal.\n",
            "\n",
            "---\n",
            "\n",
            "### 4. What are the Challenges / Risks?\n",
            "\n",
            "*   **Hallucinations:**\n",
            "    *   **Simple Idea:** When the AI **confidently makes up false information** that sounds plausible but isn't true.\n",
            "    *   **Analogy:** A very confident student who just guesses the answer and presents it as fact.\n",
            "*   **Bias:**\n",
            "    *   **Simple Idea:** The AI can pick up and reflect **biases present in its training data**. If the data has stereotypes or unfair representations, the AI might reproduce them.\n",
            "    *   **Analogy:** If a student only reads old, biased history books, their worldview might become biased.\n",
            "*   **Ethical Concerns:**\n",
            "    *   **Simple Idea:** Worries about things like **misinformation**, creating realistic \"deepfakes\" (fake videos/audio), job displacement, and copyright issues.\n",
            "*   **Security & Privacy:**\n",
            "    *   **Simple Idea:** If you put sensitive company data into a public GenAI tool, it might learn from it or expose it.\n",
            "\n",
            "---\n",
            "\n",
            "### 5. What an Interviewer Wants to Know (Why they ask these questions):\n",
            "\n",
            "*   **Do you understand the basics?** (What it is, how it generally works).\n",
            "*   **Can you think of practical applications?** (How could *you* use it in this job/company?).\n",
            "*   **Are you aware of its limitations and risks?** (You know it's powerful, but not perfect).\n",
            "*   **Can you think of ways to make it better or safer?** (Like using RAG, good prompt engineering, or fine-tuning).\n",
            "*   **Are you excited and curious about it?** (GenAI is evolving fast, so enthusiasm for learning is key).\n",
            "\n",
            "---\n",
            "\n",
            "In short, GenAI is about *creation*. It's a powerful tool with huge potential, but it's important to understand both its strengths and its weaknesses to use it effectively and responsibly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Started RAG basic building blocks and concepts\n"
      ],
      "metadata": {
        "id": "IxU_dafHQ5_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TwPvyy7sKWdL",
        "outputId": "e956abe3-135a-4fee-dc8b-b61caaba5ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.2.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.56)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"genai_notes.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "LangChain is a framework for building applications using large language models.\n",
        "It provides tools for prompt management, memory, retrieval, and agents.\n",
        "RAG helps reduce hallucinations by grounding answers in documents.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "ruQagvd3OAP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import TextLoader\n"
      ],
      "metadata": {
        "id": "zo7j1KadOz7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"genai_notes.txt\")\n",
        "documents = loader.load()\n"
      ],
      "metadata": {
        "id": "YWKM2EjPO2JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(documents))\n",
        "print(len(documents))\n",
        "print(type(documents[0]))\n",
        "print(documents[0].page_content)\n",
        "print(documents[0].metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgJ8FFOCQpdl",
        "outputId": "7eb56744-4a6b-4c40-c290-28e5611f2fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "1\n",
            "<class 'langchain_core.documents.base.Document'>\n",
            "\n",
            "LangChain is a framework for building applications using large language models.\n",
            "It provides tools for prompt management, memory, retrieval, and agents.\n",
            "RAG helps reduce hallucinations by grounding answers in documents.\n",
            "\n",
            "{'source': 'genai_notes.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
      ],
      "metadata": {
        "id": "PvWQTS4CQugs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Wk0B_PIRS3qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = text_splitter.split_documents(documents)\n"
      ],
      "metadata": {
        "id": "AlgfbgUXTBJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(chunks))\n",
        "print(type(chunks[0]))\n",
        "print(chunks[0].page_content)\n",
        "print(chunks[0].metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD2Xz7M6TJZI",
        "outputId": "b1ab5e46-d783-472a-ee53-df1dd4ffd9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "<class 'langchain_core.documents.base.Document'>\n",
            "LangChain is a framework for building applications using large language models.\n",
            "It provides tools for prompt management, memory, retrieval, and agents.\n",
            "RAG helps reduce hallucinations by grounding answers in documents.\n",
            "{'source': 'genai_notes.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5cvZR5dDTusZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}